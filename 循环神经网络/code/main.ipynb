{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import torch\n",
    "\n",
    "# Convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # Input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # Forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # Put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # Drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollution</th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_dir</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-23</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>231.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>237.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>242.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>246.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>249.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43800 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pollution  dew  temp   press wnd_dir  wnd_spd  snow  rain\n",
       "date                                                                          \n",
       "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0      SE     1.79     0     0\n",
       "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0      SE     2.68     0     0\n",
       "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0      SE     3.57     0     0\n",
       "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0      SE     5.36     1     0\n",
       "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0      SE     6.25     2     0\n",
       "...                        ...  ...   ...     ...     ...      ...   ...   ...\n",
       "2014-12-31 19:00:00        8.0  -23  -2.0  1034.0      NW   231.97     0     0\n",
       "2014-12-31 20:00:00       10.0  -22  -3.0  1034.0      NW   237.78     0     0\n",
       "2014-12-31 21:00:00       10.0  -22  -3.0  1034.0      NW   242.70     0     0\n",
       "2014-12-31 22:00:00        8.0  -22  -4.0  1034.0      NW   246.72     0     0\n",
       "2014-12-31 23:00:00       12.0  -21  -3.0  1034.0      NW   249.85     0     0\n",
       "\n",
       "[43800 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_csv('../data/pollution.csv', header=0, index_col=0)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12977867, 0.35294122, 0.24590163, ..., 0.00229001, 0.        ,\n",
       "        0.        ],\n",
       "       [0.14889336, 0.36764708, 0.24590163, ..., 0.00381099, 0.        ,\n",
       "        0.        ],\n",
       "       [0.15995975, 0.4264706 , 0.22950819, ..., 0.00533197, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.01006036, 0.2647059 , 0.26229507, ..., 0.41399646, 0.        ,\n",
       "        0.        ],\n",
       "       [0.00804829, 0.2647059 , 0.24590163, ..., 0.4208665 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.01207243, 0.2794118 , 0.26229507, ..., 0.42621556, 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = dataset.values\n",
    "\n",
    "# Integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:, 4] = encoder.fit_transform(values[:, 4])\n",
    "\n",
    "# Ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "      <th>var8(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129779</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109658</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43795</th>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.763638</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.385730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.395659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43796</th>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.395659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.405588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43797</th>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.405588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.413996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43798</th>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.413996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.420866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43799</th>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.420866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012072</td>\n",
       "      <td>0.279412</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.426216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43799 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
       "1       0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   \n",
       "2       0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   \n",
       "3       0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   \n",
       "4       0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   \n",
       "5       0.138833   0.485294   0.229508   0.563637   0.666667   0.009912   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "43795   0.010060   0.264706   0.278689   0.763638   0.333333   0.385730   \n",
       "43796   0.008048   0.250000   0.278689   0.781818   0.333333   0.395659   \n",
       "43797   0.010060   0.264706   0.262295   0.781818   0.333333   0.405588   \n",
       "43798   0.010060   0.264706   0.262295   0.781818   0.333333   0.413996   \n",
       "43799   0.008048   0.264706   0.245902   0.781818   0.333333   0.420866   \n",
       "\n",
       "       var7(t-1)  var8(t-1)   var1(t)   var2(t)   var3(t)   var4(t)   var5(t)  \\\n",
       "1       0.000000        0.0  0.148893  0.367647  0.245902  0.527273  0.666667   \n",
       "2       0.000000        0.0  0.159960  0.426471  0.229508  0.545454  0.666667   \n",
       "3       0.000000        0.0  0.182093  0.485294  0.229508  0.563637  0.666667   \n",
       "4       0.037037        0.0  0.138833  0.485294  0.229508  0.563637  0.666667   \n",
       "5       0.074074        0.0  0.109658  0.485294  0.213115  0.563637  0.666667   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "43795   0.000000        0.0  0.008048  0.250000  0.278689  0.781818  0.333333   \n",
       "43796   0.000000        0.0  0.010060  0.264706  0.262295  0.781818  0.333333   \n",
       "43797   0.000000        0.0  0.010060  0.264706  0.262295  0.781818  0.333333   \n",
       "43798   0.000000        0.0  0.008048  0.264706  0.245902  0.781818  0.333333   \n",
       "43799   0.000000        0.0  0.012072  0.279412  0.262295  0.781818  0.333333   \n",
       "\n",
       "        var6(t)   var7(t)  var8(t)  \n",
       "1      0.003811  0.000000      0.0  \n",
       "2      0.005332  0.000000      0.0  \n",
       "3      0.008391  0.037037      0.0  \n",
       "4      0.009912  0.074074      0.0  \n",
       "5      0.011433  0.111111      0.0  \n",
       "...         ...       ...      ...  \n",
       "43795  0.395659  0.000000      0.0  \n",
       "43796  0.405588  0.000000      0.0  \n",
       "43797  0.413996  0.000000      0.0  \n",
       "43798  0.420866  0.000000      0.0  \n",
       "43799  0.426216  0.000000      0.0  \n",
       "\n",
       "[43799 rows x 16 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "\n",
    "reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129779</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43795</th>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.763638</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.385730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43796</th>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.278689</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.395659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43797</th>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.405588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43798</th>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.413996</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43799</th>\n",
       "      <td>0.008048</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.420866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43799 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
       "1       0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   \n",
       "2       0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   \n",
       "3       0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   \n",
       "4       0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   \n",
       "5       0.138833   0.485294   0.229508   0.563637   0.666667   0.009912   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "43795   0.010060   0.264706   0.278689   0.763638   0.333333   0.385730   \n",
       "43796   0.008048   0.250000   0.278689   0.781818   0.333333   0.395659   \n",
       "43797   0.010060   0.264706   0.262295   0.781818   0.333333   0.405588   \n",
       "43798   0.010060   0.264706   0.262295   0.781818   0.333333   0.413996   \n",
       "43799   0.008048   0.264706   0.245902   0.781818   0.333333   0.420866   \n",
       "\n",
       "       var7(t-1)  var8(t-1)   var1(t)  \n",
       "1       0.000000        0.0  0.148893  \n",
       "2       0.000000        0.0  0.159960  \n",
       "3       0.000000        0.0  0.182093  \n",
       "4       0.037037        0.0  0.138833  \n",
       "5       0.074074        0.0  0.109658  \n",
       "...          ...        ...       ...  \n",
       "43795   0.000000        0.0  0.008048  \n",
       "43796   0.000000        0.0  0.010060  \n",
       "43797   0.000000        0.0  0.010060  \n",
       "43798   0.000000        0.0  0.008048  \n",
       "43799   0.000000        0.0  0.012072  \n",
       "\n",
       "[43799 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[9, 10, 11, 12, 13, 14, 15]], axis=1, inplace=True)\n",
    "reframed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12977867, 0.35294122, 0.24590163, ..., 0.        , 0.        ,\n",
       "        0.14889336],\n",
       "       [0.14889336, 0.36764708, 0.24590163, ..., 0.        , 0.        ,\n",
       "        0.15995975],\n",
       "       [0.15995975, 0.4264706 , 0.22950819, ..., 0.        , 0.        ,\n",
       "        0.18209255],\n",
       "       ...,\n",
       "       [0.        , 0.32352942, 0.22950819, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.32352942, 0.16393442, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.33823532, 0.1967213 , ..., 0.        , 0.        ,\n",
       "        0.0362173 ]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8760, 1, 8]) torch.Size([8760, 1]) torch.Size([35039, 1, 8]) torch.Size([35039, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# Reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_X = torch.tensor(train_X, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32).view(-1, 1)\n",
    "test_X = torch.tensor(test_X, dtype=torch.float32)\n",
    "test_y = torch.tensor(test_y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the LSTM model\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, (hn, _) = self.lstm(x)\n",
    "        out = self.fc(hn[-1])\n",
    "        return out\n",
    "\n",
    "input_dim = train_X.shape[2]\n",
    "hidden_dim = 50\n",
    "output_dim = 1\n",
    "\n",
    "model = LSTMModel(input_dim, hidden_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.0072\n",
      "Epoch 2/50, Loss: 0.0031\n",
      "Epoch 3/50, Loss: 0.0011\n",
      "Epoch 4/50, Loss: 0.0010\n",
      "Epoch 5/50, Loss: 0.0010\n",
      "Epoch 6/50, Loss: 0.0010\n",
      "Epoch 7/50, Loss: 0.0010\n",
      "Epoch 8/50, Loss: 0.0010\n",
      "Epoch 9/50, Loss: 0.0010\n",
      "Epoch 10/50, Loss: 0.0010\n",
      "Epoch 11/50, Loss: 0.0010\n",
      "Epoch 12/50, Loss: 0.0010\n",
      "Epoch 13/50, Loss: 0.0010\n",
      "Epoch 14/50, Loss: 0.0010\n",
      "Epoch 15/50, Loss: 0.0010\n",
      "Epoch 16/50, Loss: 0.0009\n",
      "Epoch 17/50, Loss: 0.0010\n",
      "Epoch 18/50, Loss: 0.0009\n",
      "Epoch 19/50, Loss: 0.0010\n",
      "Epoch 20/50, Loss: 0.0009\n",
      "Epoch 21/50, Loss: 0.0010\n",
      "Epoch 22/50, Loss: 0.0010\n",
      "Epoch 23/50, Loss: 0.0009\n",
      "Epoch 24/50, Loss: 0.0009\n",
      "Epoch 25/50, Loss: 0.0009\n",
      "Epoch 26/50, Loss: 0.0009\n",
      "Epoch 27/50, Loss: 0.0009\n",
      "Epoch 28/50, Loss: 0.0009\n",
      "Epoch 29/50, Loss: 0.0009\n",
      "Epoch 30/50, Loss: 0.0009\n",
      "Epoch 31/50, Loss: 0.0009\n",
      "Epoch 32/50, Loss: 0.0010\n",
      "Epoch 33/50, Loss: 0.0009\n",
      "Epoch 34/50, Loss: 0.0009\n",
      "Epoch 35/50, Loss: 0.0009\n",
      "Epoch 36/50, Loss: 0.0009\n",
      "Epoch 37/50, Loss: 0.0009\n",
      "Epoch 38/50, Loss: 0.0009\n",
      "Epoch 39/50, Loss: 0.0009\n",
      "Epoch 40/50, Loss: 0.0009\n",
      "Epoch 41/50, Loss: 0.0009\n",
      "Epoch 42/50, Loss: 0.0009\n",
      "Epoch 43/50, Loss: 0.0009\n",
      "Epoch 44/50, Loss: 0.0009\n",
      "Epoch 45/50, Loss: 0.0009\n",
      "Epoch 46/50, Loss: 0.0009\n",
      "Epoch 47/50, Loss: 0.0009\n",
      "Epoch 48/50, Loss: 0.0009\n",
      "Epoch 49/50, Loss: 0.0009\n",
      "Epoch 50/50, Loss: 0.0009\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBjklEQVR4nO3de3zT9aH/8XcuzaWlLYVq00KFOqvouClILeN3cMduZeNs1l0Osp2BjMku6mBVmXCgeNvqA4cHEbbOxzY97nEYyDaZxykbpzrnpCtyc2NOhw4tCikgtinpJW3y/f2RJjVaqmmTb9ryej4e30fSbz755pNvA3n3c/taDMMwBAAAMMRZU10BAACARCDUAACAYYFQAwAAhgVCDQAAGBYINQAAYFgg1AAAgGGBUAMAAIYFQg0AABgW7KmugFlCoZCOHj2qzMxMWSyWVFcHAAB8CIZhqKWlRQUFBbJa+26LOWtCzdGjR1VYWJjqagAAgH44cuSIxo4d22eZsybUZGZmSgqflKysrBTXBgAAfBg+n0+FhYXR7/G+nDWhJtLllJWVRagBAGCI+TBDRxgoDAAAhgVCDQAAGBYINQAAYFg4a8bUAACGD8Mw1NXVpWAwmOqqYIBsNpvsdntCllsh1AAAhpRAIKBjx46ptbU11VVBgqSnpys/P18Oh2NAxyHUAACGjFAopMOHD8tms6mgoEAOh4MFVYcwwzAUCAR04sQJHT58WMXFxR+4wF5fCDUAgCEjEAgoFAqpsLBQ6enpqa4OEsDtdistLU1vvPGGAoGAXC5Xv4/FQGEAwJAzkL/mMfgk6vfJpwIAAAwLhBoAADAsEGoAABiixo8fr/Xr16e6GoMGoQYAgCSzWCx9brfffnu/jvvCCy9oyZIlA6rblVdeqWXLlg3oGIMFs58G6FBji7a8cETnZDr1jdkfSXV1AACD0LFjx6L3t27dqqqqKr3yyivRfSNGjIjeNwxDwWBQdvsHf0Wfc845ia3oEEdLzQAdbW7XT/90WL85cDTVVQGAs5JhGGoNdJm+GYbxoevo8XiiW3Z2tiwWS/Tnl19+WZmZmXrqqac0bdo0OZ1O/elPf9Jrr72mq6++Wnl5eRoxYoQuv/xy/d///V/Mcd/b/WSxWPSTn/xE11xzjdLT01VcXKzHH398QOf3V7/6lT760Y/K6XRq/PjxWrduXczjP/zhD1VcXCyXy6W8vDx94QtfiD72y1/+UpMmTZLb7dbo0aNVVlYmv98/oPr0hZaaAUp32CRJ7Z0s1Q0AqdDWGdQlVb8z/XVfurNc6Y7EfY3edttt+sEPfqDzzz9fOTk5OnLkiD796U/re9/7npxOpx555BF95jOf0SuvvKLzzjvvjMe54447tHbtWt1777164IEH9OUvf1lvvPGGRo0aFXed9u7dq3//93/X7bffrnnz5mnXrl361re+pdGjR+u6667Tnj179O1vf1s///nPNXPmTJ06dUrPPfecpHDr1Pz587V27Vpdc801amlp0XPPPRdXGIwXoWaA3GnhUNMa6EpxTQAAQ9mdd96pT3ziE9GfR40apSlTpkR/vuuuu/TYY4/p8ccf14033njG41x33XWaP3++JOn73/++NmzYoN27d2vOnDlx1+m+++7TVVddpdWrV0uSLrzwQr300ku69957dd1116mhoUEZGRn6t3/7N2VmZmrcuHG69NJLJYVDTVdXlz73uc9p3LhxkqRJkybFXYd4EGoGyO2IhBpaagAgFdxpNr10Z3lKXjeRpk+fHvPz6dOndfvtt+u3v/1tNCC0tbWpoaGhz+NMnjw5ej8jI0NZWVk6fvx4v+r097//XVdffXXMvo997GNav369gsGgPvGJT2jcuHE6//zzNWfOHM2ZMyfa9TVlyhRdddVVmjRpksrLy/XJT35SX/jCF5STk9OvunwYjKkZoEj3UxuhBgBSwmKxKN1hN31L9DWnMjIyYn6+5ZZb9Nhjj+n73/++nnvuOR04cECTJk1SIBDo8zhpaWnvOz+hUCihdY3IzMzUvn379Itf/EL5+fmqqqrSlClT1NTUJJvNpp07d+qpp57SJZdcogceeEAXXXSRDh8+nJS6SISaAUtPCzd2dYUMdQaT86EBAJx9nn/+eV133XW65pprNGnSJHk8Hr3++uum1uHiiy/W888//756XXjhhbLZwn/U2+12lZWVae3atfrLX/6i119/XU8//bSkcKD62Mc+pjvuuEP79++Xw+HQY489lrT60v00QJHuJyncBZXtJicCAAauuLhYv/71r/WZz3xGFotFq1evTlqLy4kTJ3TgwIGYffn5+br55pt1+eWX66677tK8efNUV1enjRs36oc//KEk6YknntA///lP/cu//ItycnL05JNPKhQK6aKLLlJ9fb1qa2v1yU9+Uueee67q6+t14sQJXXzxxUl5DxKhZsDSbBbZrBYFQ4baAkFlu9M++EkAAHyA++67T1/96lc1c+ZM5ebm6rvf/a58Pl9SXmvz5s3avHlzzL677rpLq1at0qOPPqqqqirdddddys/P15133qnrrrtOkjRy5Ej9+te/1u2336729nYVFxfrF7/4hT760Y/q73//u/74xz9q/fr18vl8GjdunNatW6dPfepTSXkPkiSjHzZu3GiMGzfOcDqdxowZM4z6+vo+yz/66KPGRRddZDidTmPixInGb3/725jHQ6GQsXr1asPj8Rgul8u46qqrjH/84x/Rx5955hlDUq/b7t27P1Sdm5ubDUlGc3Nz/G/4A0ys2mGM++4TxmvHWxJ+bABAj7a2NuOll14y2traUl0VJFBfv9d4vr/j7ivZunWrKisrtWbNGu3bt09TpkxReXn5GUdW79q1S/Pnz9fixYu1f/9+VVRUqKKiQgcPHoyWWbt2rTZs2KCamhrV19crIyND5eXlam9vlyTNnDlTx44di9m+9rWvqaio6H2jxVMh0gXVxlo1AACkTNyh5r777tP111+vRYsW6ZJLLlFNTY3S09P1s5/9rNfy999/v+bMmaNbb71VF198se666y5ddtll2rhxo6TwSpDr16/XqlWrdPXVV2vy5Ml65JFHdPToUW3fvl2S5HA4YlZjHD16tH7zm99o0aJFCR993h9uZkABAJBycYWaQCCgvXv3qqysrOcAVqvKyspUV1fX63Pq6upiyktSeXl5tPzhw4fl9XpjymRnZ6ukpOSMx3z88cf19ttva9GiRWesa0dHh3w+X8yWLD0L8BFqAABIlbhCzcmTJxUMBpWXlxezPy8vT16vt9fneL3ePstHbuM55k9/+lOVl5dr7NixZ6xrdXW1srOzo1thYWHfb24A0lmADwCAlBty84/ffPNN/e53v9PixYv7LLdixQo1NzdHtyNHjiStTpFrf3D9JwAwh5HE6wfBfIn6fcYVanJzc2Wz2dTY2Bizv7GxUR6Pp9fneDyePstHbj/sMR966CGNHj1an/3sZ/usq9PpVFZWVsyWLC66nwDAFJHVcltbW1NcEyRS5Pf53tWQ4xXXOjUOh0PTpk1TbW2tKioqJEmhUEi1tbVnvLhWaWmpamtrtWzZsui+nTt3qrS0VJJUVFQkj8ej2tpaTZ06VZLk8/lUX1+vb37zmzHHMgxDDz30kBYsWDDgN55IPd1PXNQSAJLJZrNp5MiR0Rm36enpg2LCCPrHMAy1trbq+PHjGjlyZHSV4v6Ke/G9yspKLVy4UNOnT9eMGTO0fv16+f3+6KDdBQsWaMyYMaqurpYkLV26VLNnz9a6des0d+5cbdmyRXv27NGDDz4oKbyE8rJly3T33XeruLhYRUVFWr16tQoKCqLBKeLpp5/W4cOH9bWvfW1AbzrRuP4TAJgn0orf34s0YvAZOXLkGXt84hF3qJk3b55OnDihqqoqeb1eTZ06VTt27IgO9G1oaJDV2tOrNXPmTG3evFmrVq3SypUrVVxcrO3bt2vixInRMsuXL5ff79eSJUvU1NSkWbNmaceOHXK5XDGv/dOf/lQzZ87UhAkT+vt+k4J1agDAPBaLRfn5+Tr33HPV2dmZ6upggNLS0gbcQhNhMc6S0VY+n0/Z2dlqbm5O+PiatTte1g//8Jqumzlet3/2owk9NgAAZ7N4vr+H3OynwYjuJwAAUo9QkwDu7inddD8BAJA6hJoEYPE9AABSj1CTAJHLJLR1MqUbAIBUIdQkgJuWGgAAUo5QkwAMFAYAIPUINQmQzjo1AACkHKEmAbj2EwAAqUeoSYDIVbrpfgIAIHUINQnw7u6ns2SBZgAABh1CTQJEZj8FQ4YCwVCKawMAwNmJUJMAkXVqJLqgAABIFUJNAqTZrEqzWSQxWBgAgFQh1CRIz6rChBoAAFKBUJMgbhbgAwAgpQg1CRKZ1k33EwAAqUGoSRB3dAE+LmoJAEAqEGoSJLJWTTtjagAASAlCTYJwpW4AAFKLUJMgbq7/BABAShFqEoTuJwAAUotQkyBuZj8BAJBShJoEofsJAIDUItQkSPRK3UzpBgAgJQg1CRJdUZgxNQAApAShJkHSmdINAEBKEWoSJHpBS0INAAApQahJEBbfAwAgtQg1CRK5oCVjagAASA1CTYL0zH4i1AAAkAqEmgRxRdap6WRKNwAAqUCoSRBaagAASC1CTYIQagAASC1CTYJEZz91BmUYRoprAwDA2YdQkyCRdWoMQ+roCqW4NgAAnH0INQkSmdItsVYNAACpQKhJEJvVIoc9fDpZqwYAAPMRahKo51IJTOsGAMBshJoE4qKWAACkDqEmgdxM6wYAIGUINQmU/q5p3QAAwFyEmgTqGVNDqAEAwGyEmgRyd0/rZkwNAADm61eo2bRpk8aPHy+Xy6WSkhLt3r27z/Lbtm3ThAkT5HK5NGnSJD355JMxjxuGoaqqKuXn58vtdqusrEyHDh1633F++9vfqqSkRG63Wzk5OaqoqOhP9ZMmPdJSQ/cTAACmizvUbN26VZWVlVqzZo327dunKVOmqLy8XMePH++1/K5duzR//nwtXrxY+/fvV0VFhSoqKnTw4MFombVr12rDhg2qqalRfX29MjIyVF5ervb29miZX/3qV/rKV76iRYsW6cUXX9Tzzz+vL33pS/14y8nTc/0npnQDAGA2ixHnhYpKSkp0+eWXa+PGjZKkUCikwsJC3XTTTbrtttveV37evHny+/164oknovuuuOIKTZ06VTU1NTIMQwUFBbr55pt1yy23SJKam5uVl5enhx9+WNdee626uro0fvx43XHHHVq8eHG/3qjP51N2draam5uVlZXVr2N8kJWP/VWb6xu0rKxYy8ouTMprAABwNonn+zuulppAIKC9e/eqrKys5wBWq8rKylRXV9frc+rq6mLKS1J5eXm0/OHDh+X1emPKZGdnq6SkJFpm3759euutt2S1WnXppZcqPz9fn/rUp2Jae96ro6NDPp8vZku2dAYKAwCQMnGFmpMnTyoYDCovLy9mf15enrxeb6/P8Xq9fZaP3PZV5p///Kck6fbbb9eqVav0xBNPKCcnR1deeaVOnTrV6+tWV1crOzs7uhUWFsbzVvsl2v3EmBoAAEw3JGY/hULhq17/53/+pz7/+c9r2rRpeuihh2SxWLRt27Zen7NixQo1NzdHtyNHjiS9nsx+AgAgdeIKNbm5ubLZbGpsbIzZ39jYKI/H0+tzPB5Pn+Ujt32Vyc/PlyRdcskl0cedTqfOP/98NTQ09Pq6TqdTWVlZMVuyudO6L2hJqAEAwHRxhRqHw6Fp06aptrY2ui8UCqm2tlalpaW9Pqe0tDSmvCTt3LkzWr6oqEgejyemjM/nU319fbTMtGnT5HQ69corr0TLdHZ26vXXX9e4cePieQtJlR5tqWH2EwAAZrPH+4TKykotXLhQ06dP14wZM7R+/Xr5/X4tWrRIkrRgwQKNGTNG1dXVkqSlS5dq9uzZWrdunebOnastW7Zoz549evDBByVJFotFy5Yt0913363i4mIVFRVp9erVKigoiK5Dk5WVpW984xtas2aNCgsLNW7cON17772SpC9+8YuJOA8J4WZMDQAAKRN3qJk3b55OnDihqqoqeb1eTZ06VTt27IgO9G1oaJDV2tMANHPmTG3evFmrVq3SypUrVVxcrO3bt2vixInRMsuXL5ff79eSJUvU1NSkWbNmaceOHXK5XNEy9957r+x2u77yla+ora1NJSUlevrpp5WTkzOQ959Q6VzQEgCAlIl7nZqhyox1ana9elJf+km9is8doZ2Vs5PyGgAAnE2Stk4N+hbpfmL2EwAA5iPUJFBkoHA7Y2oAADAdoSaB3Gm01AAAkCqEmgR69+ynUOisGKoEAMCgQahJoMjsJ0nq6AqlsCYAAJx9CDUJFOl+kliADwAAsxFqEshqtchpD59SxtUAAGAuQk2CcaVuAABSg1CTYJFp3awqDACAuQg1CcYCfAAApAahJsEig4XbOhkoDACAmQg1CUZLDQAAqUGoSTCu1A0AQGoQahKM2U8AAKQGoSbBXFz/CQCAlCDUJFg6Y2oAAEgJQk2CRdapaaf7CQAAUxFqEswd7X5iSjcAAGYi1CQYU7oBAEgNQk2CMaUbAIDUINQkWM+KwoQaAADMRKhJsMhAYbqfAAAwF6EmwdyO8Cml+wkAAHMRahLMnRZuqaH7CQAAcxFqEoyBwgAApAahJsF6pnSzTg0AAGYi1CSYm2s/AQCQEoSaBIt0P3V0hRQKGSmuDQAAZw9CTYJFpnRLDBYGAMBMhJoEc9p7TildUAAAmIdQk2BWq6VnVWFCDQAApiHUJEF0WjfdTwAAmIZQkwRM6wYAwHyEmiSg+wkAAPMRapIg3cFaNQAAmI1QkwRuxtQAAGA6Qk0SRNaqofsJAADzEGqSoOdSCQwUBgDALISaJIjOfqL7CQAA0xBqkiAyULid7icAAExDqEkCN7OfAAAwHaEmCaJjauh+AgDANP0KNZs2bdL48ePlcrlUUlKi3bt391l+27ZtmjBhglwulyZNmqQnn3wy5nHDMFRVVaX8/Hy53W6VlZXp0KFDMWXGjx8vi8USs91zzz39qX7S0f0EAID54g41W7duVWVlpdasWaN9+/ZpypQpKi8v1/Hjx3stv2vXLs2fP1+LFy/W/v37VVFRoYqKCh08eDBaZu3atdqwYYNqampUX1+vjIwMlZeXq729PeZYd955p44dOxbdbrrppnirbwp395Ruup8AADBP3KHmvvvu0/XXX69FixbpkksuUU1NjdLT0/Wzn/2s1/L333+/5syZo1tvvVUXX3yx7rrrLl122WXauHGjpHArzfr167Vq1SpdffXVmjx5sh555BEdPXpU27dvjzlWZmamPB5PdMvIyIj/HZsgne4nAABMF1eoCQQC2rt3r8rKynoOYLWqrKxMdXV1vT6nrq4uprwklZeXR8sfPnxYXq83pkx2drZKSkred8x77rlHo0eP1qWXXqp7771XXV1nXgemo6NDPp8vZjNLdEVh1qkBAMA09ngKnzx5UsFgUHl5eTH78/Ly9PLLL/f6HK/X22t5r9cbfTyy70xlJOnb3/62LrvsMo0aNUq7du3SihUrdOzYMd133329vm51dbXuuOOOeN5ewnCZBAAAzBdXqEmlysrK6P3JkyfL4XDo61//uqqrq+V0Ot9XfsWKFTHP8fl8KiwsNKWu0e4nxtQAAGCauLqfcnNzZbPZ1NjYGLO/sbFRHo+n1+d4PJ4+y0du4zmmJJWUlKirq0uvv/56r487nU5lZWXFbGbp6X4i1AAAYJa4Qo3D4dC0adNUW1sb3RcKhVRbW6vS0tJen1NaWhpTXpJ27twZLV9UVCSPxxNTxufzqb6+/ozHlKQDBw7IarXq3HPPjectmCKdxfcAADBd3N1PlZWVWrhwoaZPn64ZM2Zo/fr18vv9WrRokSRpwYIFGjNmjKqrqyVJS5cu1ezZs7Vu3TrNnTtXW7Zs0Z49e/Tggw9KkiwWi5YtW6a7775bxcXFKioq0urVq1VQUKCKigpJ4cHG9fX1+vjHP67MzEzV1dXpO9/5jv7jP/5DOTk5CToViROZ0s2YGgAAzBN3qJk3b55OnDihqqoqeb1eTZ06VTt27IgO9G1oaJDV2tMANHPmTG3evFmrVq3SypUrVVxcrO3bt2vixInRMsuXL5ff79eSJUvU1NSkWbNmaceOHXK5XJLCXUlbtmzR7bffro6ODhUVFek73/lOzJiZwSQypibQFVIwZMhmtaS4RgAADH8WwzCMVFfCDD6fT9nZ2Wpubk76+Jr2zqAmrN4hSfrr7Z9Upistqa8HAMBwFc/3N9d+SgKn3SpLd+MMg4UBADAHoSYJLBZLtAuKcTUAAJiDUJMkXP8JAABzEWqSxO0In1pCDQAA5iDUJEl6Wve0bkINAACmINQkCdd/AgDAXISaJOlZVZgrdQMAYAZCTZK407j+EwAAZiLUJAndTwAAmItQkyRc1BIAAHMRapIk3cHsJwAAzESoSRJXGi01AACYiVCTJOmMqQEAwFSEmiSJhhqmdAMAYApCTZK4GSgMAICpCDVJ4uYq3QAAmIpQkyQ93U+EGgAAzECoSRJ395Ruup8AADAHoSZJ6H4CAMBchJok4YKWAACYi1CTJG7G1AAAYCpCTZKw+B4AAOYi1CRJZExNZ9BQZzCU4toAADD8EWqSJNL9JDEDCgAAMxBqksRhs8pmtUiS2umCAgAg6Qg1SWKxWJTOlboBADANoSaJXEzrBgDANISaJIrMgKL7CQCA5CPUJJGb7icAAExDqEminlWFCTUAACQboSaJWFUYAADzEGqSyJ0WvlI3qwoDAJB8hJokovsJAADzEGqSKHr9J6Z0AwCQdISaJHIx+wkAANMQapKIK3UDAGAeQk0SpTP7CQAA0xBqksjtCM9+ovsJAIDkI9QkESsKAwBgHkJNEnHtJwAAzEOoSSI3V+kGAMA0hJokovsJAADz9CvUbNq0SePHj5fL5VJJSYl2797dZ/lt27ZpwoQJcrlcmjRpkp588smYxw3DUFVVlfLz8+V2u1VWVqZDhw71eqyOjg5NnTpVFotFBw4c6E/1TcOUbgAAzBN3qNm6dasqKyu1Zs0a7du3T1OmTFF5ebmOHz/ea/ldu3Zp/vz5Wrx4sfbv36+KigpVVFTo4MGD0TJr167Vhg0bVFNTo/r6emVkZKi8vFzt7e3vO97y5ctVUFAQb7VTggtaAgBgnrhDzX333afrr79eixYt0iWXXKKamhqlp6frZz/7Wa/l77//fs2ZM0e33nqrLr74Yt1111267LLLtHHjRknhVpr169dr1apVuvrqqzV58mQ98sgjOnr0qLZv3x5zrKeeekq///3v9YMf/CD+d5oC6d1Tugk1AAAkX1yhJhAIaO/evSorK+s5gNWqsrIy1dXV9fqcurq6mPKSVF5eHi1/+PBheb3emDLZ2dkqKSmJOWZjY6Ouv/56/fznP1d6evoH1rWjo0M+ny9mM1t0TE1nUIZhmP76AACcTeIKNSdPnlQwGFReXl7M/ry8PHm93l6f4/V6+ywfue2rjGEYuu666/SNb3xD06dP/1B1ra6uVnZ2dnQrLCz8UM9LpEj3UzBkqDNIqAEAIJmGxOynBx54QC0tLVqxYsWHfs6KFSvU3Nwc3Y4cOZLEGvYuMlBYogsKAIBkiyvU5ObmymazqbGxMWZ/Y2OjPB5Pr8/xeDx9lo/c9lXm6aefVl1dnZxOp+x2uy644AJJ0vTp07Vw4cJeX9fpdCorKytmM1uazao0m0WS1NrJWjUAACRTXKHG4XBo2rRpqq2tje4LhUKqra1VaWlpr88pLS2NKS9JO3fujJYvKiqSx+OJKePz+VRfXx8ts2HDBr344os6cOCADhw4EJ0SvnXrVn3ve9+L5y2YzsVaNQAAmMIe7xMqKyu1cOFCTZ8+XTNmzND69evl9/u1aNEiSdKCBQs0ZswYVVdXS5KWLl2q2bNna926dZo7d662bNmiPXv26MEHH5QkWSwWLVu2THfffbeKi4tVVFSk1atXq6CgQBUVFZKk8847L6YOI0aMkCR95CMf0dixY/v95s2Q7rCppb2L7icAAJIs7lAzb948nThxQlVVVfJ6vZo6dap27NgRHejb0NAgq7WnAWjmzJnavHmzVq1apZUrV6q4uFjbt2/XxIkTo2WWL18uv9+vJUuWqKmpSbNmzdKOHTvkcrkS8BZTKzytu4MF+AAASDKLcZbMNfb5fMrOzlZzc7Op42s+ff9zeumYT//91RmafeE5pr0uAADDQTzf30Ni9tNQ1rOqMAOFAQBIJkJNknH9JwAAzEGoSTKu1A0AgDkINUmWzkUtAQAwBaEmySJjamipAQAguQg1SeZO675SN2NqAABIKkJNktH9BACAOQg1SdbT/cSUbgAAkolQk2TMfgIAwByEmiSLdD+1M6YGAICkItQkGbOfAAAwB6Emyeh+AgDAHISaJAtfpZvuJwAAko1Qk2R0PwEAYA5CTZKlE2oAADAFoSbJImNq2linBgCApCLUJFl0ReHOoAzDSHFtAAAYvgg1SRYZUxMypI6uUIprAwDA8EWoSbJI95PE9Z8AAEgmQk2S2W1WOWzh09zKtG4AAJKGUGMCN1fqBgAg6Qg1Jkgn1AAAkHSEGhP0LMDHtG4AAJKFUGOC6PWfGFMDAEDSEGpMEOl+aqf7CQCApCHUmMDdfVFLLpUAAEDyEGpMkE73EwAASUeoMUHPlG4GCgMAkCyEGhP0hBoukwAAQLIQakzQ0/1ESw0AAMlCqDEBi+8BAJB8hBoTuAg1AAAkHaHGBMx+AgAg+Qg1JkjvXqeGlhoAAJKHUGMCF9d+AgAg6Qg1Joh0P7V1MqUbAIBkIdSYIJ3F9wAASDpCjQnc0e4nxtQAAJAshBoTuJnSDQBA0hFqTJCe1j37iSndAAAkDaHGBNGWms6gQiEjxbUBAGB4ItSYINudJkkyDKm5rTPFtQEAYHjqV6jZtGmTxo8fL5fLpZKSEu3evbvP8tu2bdOECRPkcrk0adIkPfnkkzGPG4ahqqoq5efny+12q6ysTIcOHYop89nPflbnnXeeXC6X8vPz9ZWvfEVHjx7tT/VN57BbleUKd0G97e9IcW0AABie4g41W7duVWVlpdasWaN9+/ZpypQpKi8v1/Hjx3stv2vXLs2fP1+LFy/W/v37VVFRoYqKCh08eDBaZu3atdqwYYNqampUX1+vjIwMlZeXq729PVrm4x//uB599FG98sor+tWvfqXXXntNX/jCF/rxllMjN9MpSTrREkhxTQAAGJ4shmHENcijpKREl19+uTZu3ChJCoVCKiws1E033aTbbrvtfeXnzZsnv9+vJ554Irrviiuu0NSpU1VTUyPDMFRQUKCbb75Zt9xyiySpublZeXl5evjhh3Xttdf2Wo/HH39cFRUV6ujoUFpa2gfW2+fzKTs7W83NzcrKyornLSfEv/+4TrsPn9LGL12qf5tcYPrrAwAwFMXz/R1XS00gENDevXtVVlbWcwCrVWVlZaqrq+v1OXV1dTHlJam8vDxa/vDhw/J6vTFlsrOzVVJScsZjnjp1Sv/zP/+jmTNnnjHQdHR0yOfzxWyplDvCIUk62UL3EwAAyRBXqDl58qSCwaDy8vJi9ufl5cnr9fb6HK/X22f5yO2HOeZ3v/tdZWRkaPTo0WpoaNBvfvObM9a1urpa2dnZ0a2wsPDDvckkyR0R7n46eZruJwAAkmFIzX669dZbtX//fv3+97+XzWbTggULdKbesxUrVqi5uTm6HTlyxOTaxhqdEQ41DBQGACA57PEUzs3Nlc1mU2NjY8z+xsZGeTyeXp/j8Xj6LB+5bWxsVH5+fkyZqVOnvu/1c3NzdeGFF+riiy9WYWGh/vznP6u0tPR9r+t0OuV0OuN5e0mVmxnufmKgMAAAyRFXS43D4dC0adNUW1sb3RcKhVRbW9trsJCk0tLSmPKStHPnzmj5oqIieTyemDI+n0/19fVnPGbkdaXw2JmhINL9REsNAADJEVdLjSRVVlZq4cKFmj59umbMmKH169fL7/dr0aJFkqQFCxZozJgxqq6uliQtXbpUs2fP1rp16zR37lxt2bJFe/bs0YMPPihJslgsWrZsme6++24VFxerqKhIq1evVkFBgSoqKiRJ9fX1euGFFzRr1izl5OTotdde0+rVq/WRj3ykz+AzmEQHCp8m1AAAkAxxh5p58+bpxIkTqqqqktfr1dSpU7Vjx47oQN+GhgZZrT0NQDNnztTmzZu1atUqrVy5UsXFxdq+fbsmTpwYLbN8+XL5/X4tWbJETU1NmjVrlnbs2CGXyyVJSk9P169//WutWbNGfr9f+fn5mjNnjlatWjWoupj6Em2pYaAwAABJEfc6NUNVqtepOd3RpYlrfidJeunOcqU74s6TAACcdZK2Tg36L8NhkystfLpPMlgYAICEI9SYxGKxRKd1n2SwMAAACUeoMVHk+k+sKgwAQOIRakx0TvcMqLf9dD8BAJBohBoTRbufaKkBACDhCDUmiqwqzFo1AAAkHqHGRD0Dhel+AgAg0Qg1JmKgMAAAyUOoMVEuA4UBAEgaQo2JIpdKYEwNAACJR6gxUSTUNLV2qjMYSnFtAAAYXgg1JhrpTpPNapEknaILCgCAhCLUmMhqtWhURnhczQkGCwMAkFCEGpONzmCwMAAAyUCoMdk5TOsGACApCDUmiwwWfpsrdQMAkFCEGpNFup9Onqb7CQCARCLUmIxVhQEASA5CjcmiLTUMFAYAIKEINSajpQYAgOQg1JjsHAYKAwCQFIQak42OXNTydEChkJHi2gAAMHwQakw2OiPcUtMVMtTc1pni2gAAMHwQakzmsFuV5bJLogsKAIBEItSkQGSw8IkWZkABAJAohJoUyM1gsDAAAIlGqEmB3MzutWqY1g0AQMIQalIgcv0nLpUAAEDiEGpSYDTdTwAAJByhJgUi3U8MFAYAIHEINSlASw0AAIlHqEmBcyIDhU8TagAASBRCTQpEBgq/zUBhAAAShlCTAqO7Q01rIKjWQFeKawMAwPBAqEmBDIdNrrTwqT/JYGEAABKCUJMCFoslOlj4JIOFAQBICEJNikSu/8SqwgAAJAahJkVyM8IzoN720/0EAEAiEGpSJHqpBFpqAABICEJNiuSyVg0AAAlFqEmRnoHCdD8BAJAIhJoUYaAwAACJ1a9Qs2nTJo0fP14ul0slJSXavXt3n+W3bdumCRMmyOVyadKkSXryySdjHjcMQ1VVVcrPz5fb7VZZWZkOHToUffz111/X4sWLVVRUJLfbrY985CNas2aNAoGh28rBQGEAABIr7lCzdetWVVZWas2aNdq3b5+mTJmi8vJyHT9+vNfyu3bt0vz587V48WLt379fFRUVqqio0MGDB6Nl1q5dqw0bNqimpkb19fXKyMhQeXm52tvbJUkvv/yyQqGQfvzjH+tvf/ub/uu//ks1NTVauXJlP9926kVbahhTAwBAQlgMwzDieUJJSYkuv/xybdy4UZIUCoVUWFiom266Sbfddtv7ys+bN09+v19PPPFEdN8VV1yhqVOnqqamRoZhqKCgQDfffLNuueUWSVJzc7Py8vL08MMP69prr+21Hvfee69+9KMf6Z///OeHqrfP51N2draam5uVlZUVz1tOilP+gC67a6ck6dD3PqU0Gz2BAAC8Vzzf33F9kwYCAe3du1dlZWU9B7BaVVZWprq6ul6fU1dXF1NeksrLy6PlDx8+LK/XG1MmOztbJSUlZzymFA4+o0aNiqf6g8pId5psVoukcMABAAADE1eoOXnypILBoPLy8mL25+Xlyev19vocr9fbZ/nIbTzHfPXVV/XAAw/o61//+hnr2tHRIZ/PF7MNJlarRaO6x9WcYLAwAAADNuT6PN566y3NmTNHX/ziF3X99defsVx1dbWys7OjW2FhoYm1/HBGM1gYAICEiSvU5ObmymazqbGxMWZ/Y2OjPB5Pr8/xeDx9lo/cfphjHj16VB//+Mc1c+ZMPfjgg33WdcWKFWpubo5uR44c+eA3aLJzmNYNAEDCxBVqHA6Hpk2bptra2ui+UCik2tpalZaW9vqc0tLSmPKStHPnzmj5oqIieTyemDI+n0/19fUxx3zrrbd05ZVXatq0aXrooYdktfZddafTqaysrJhtsOlpqSHUAAAwUPZ4n1BZWamFCxdq+vTpmjFjhtavXy+/369FixZJkhYsWKAxY8aourpakrR06VLNnj1b69at09y5c7Vlyxbt2bMn2tJisVi0bNky3X333SouLlZRUZFWr16tgoICVVRUSOoJNOPGjdMPfvADnThxIlqfM7UQDQXR6z+dpvsJAICBijvUzJs3TydOnFBVVZW8Xq+mTp2qHTt2RAf6NjQ0xLSizJw5U5s3b9aqVau0cuVKFRcXa/v27Zo4cWK0zPLly+X3+7VkyRI1NTVp1qxZ2rFjh1wul6Rwy86rr76qV199VWPHjo2pT5wz0gcVVhUGACBx4l6nZqgabOvUSNK2PUd06y//on+58Bw98tUZqa4OAACDTtLWqUFi0VIDAEDiEGpSKLf7St0MFAYAYOAINSmUm9k9++l0QKHQWdELCABA0hBqUiiyonBXyFBzW2eKawMAwNBGqEkhp92mLFd4AhpdUAAADAyhJsUig4VPtLBWDQAAA0GoSTEGCwMAkBiEmhSLDBZmWjcAAANDqEmx0RlcKgEAgEQg1KRY5PpPdD8BADAwhJoUi3Q/MVAYAICBIdSk2GgGCgMAkBCEmhQ7JzJQ+DShBgCAgSDUpFi0pYaBwgAADAihJsUii++1BoJqDXSluDYAAAxdhJoUy3DY5LSHfw0nGSwMAEC/EWpSzGKxRKd1n2SwMAAA/UaoGQQiXVCsKgwAQP8RagaB3IzwDKi3/XQ/AQDQX4SaQSDa/URLDQAA/UaoGQRGj2CtGgAABopQMwj0DBSm+wkAgP4i1AwCDBQGAGDgCDWDAAOFAQAYOELNIBBtqWFMDQAA/UaoGQRGd7fUNLV2qjMYSnFtAAAYmgg1g0BOukNWS/j+KbqgAADoF0LNIGC1WjSq+2rdJxgsDABAvxBqBoncEQwWBgBgIAg1g8Q5TOsGAGBACDWDxOjotG5CDQAA/UGoGSSiqwqfpvsJAID+INQMEqO5qCUAAANCqBkkIgOFuf4TAAD9Q6gZJLj+EwAAA0OoGSRyu9epYaAwAAD9Q6gZJHIzu2c/nQ4oFDJSXBsAAIYeQs0gMap7SndXyFBzW2eKawMAwNBDqBkknHabslx2SdKLbzaltjIAAAxBhJpB5PLxoyRJX/vvPfrxs6/RDQUAQBwINYPIffOmau6kfHWFDFU/9bKue/gFnTzNwGEAAD4MQs0gku1O08YvXarvXzNJTrtVf/zHCX3q/uf0p0MnU101AAAGPULNIGOxWPSlkvP0+I2zdGHeCJ1o6dBXflave3/3sjqDoVRXDwCAQatfoWbTpk0aP368XC6XSkpKtHv37j7Lb9u2TRMmTJDL5dKkSZP05JNPxjxuGIaqqqqUn58vt9utsrIyHTp0KKbM9773Pc2cOVPp6ekaOXJkf6o9pFzkydRvbpil+TPOk2FIm555TfN+XKc332lNddUAABiU4g41W7duVWVlpdasWaN9+/ZpypQpKi8v1/Hjx3stv2vXLs2fP1+LFy/W/v37VVFRoYqKCh08eDBaZu3atdqwYYNqampUX1+vjIwMlZeXq729PVomEAjoi1/8or75zW/2420OTW6HTdWfm6RNX7pMmU679jU06dP3P6f/ffGo/B1dqa4eAACDisUwjLim2JSUlOjyyy/Xxo0bJUmhUEiFhYW66aabdNttt72v/Lx58+T3+/XEE09E911xxRWaOnWqampqZBiGCgoKdPPNN+uWW26RJDU3NysvL08PP/ywrr322pjjPfzww1q2bJmamprieqM+n0/Z2dlqbm5WVlZWXM8dDI6catWNv9ivF480RfdluuzKz3bJk+2WJ8spT7a7+2eX8rNdGjPSrUxXWuoqDQDAAMXz/W2P58CBQEB79+7VihUrovusVqvKyspUV1fX63Pq6upUWVkZs6+8vFzbt2+XJB0+fFher1dlZWXRx7Ozs1VSUqK6urr3hZoPq6OjQx0dPTOHfD5fv44zWBSOStcvv1Gq+3b+Q//z5zfka+9SS3uXWtpP6x+Np8/4vJHpaRqb49bYkekqHOXW2Jx0jc1xq3BUusaMdCvDGddH4H0Mw1DIkCySrFbLgI4FAMBAxPWNdvLkSQWDQeXl5cXsz8vL08svv9zrc7xeb6/lvV5v9PHIvjOV6Y/q6mrdcccd/X7+YJRms+q7cybou3MmqKW9U42+dh1rbpe3ezvma1djc3jfseY2vdPaqabu7eBbvYc6i0WyWiyyWsKDlG3d960WS/ix7qASDBkKhcIBJmiE7wcNQ5F2PotFynTalZ2epmx37JbVfTvCaVdX0FBXKKTOoKHOYKh767kfDBmSLLJbLbK9d7P03JekUHegCtcrfD8csgwFQ5IrzapRGY7oNjrDqVEjHBqd4ZArzWbGr+xDa+8MqtHXrkZfh6wWaWxOus7NdBIUEdUWCOrg0Wa9eKRJf32rWSFDmjI2W5eNy9FHC7LktA+uzzSQCgP7M30QW7FiRUwLkc/nU2FhYQprlFiZrjRlutJ0wbmZZyxzuqNLb73TpjffadWRU6168502HXknfPvmO21qbuuU0R1SgpKk/i/2ZxiSr71LvvYuHVFbv49jFneaTaMyHMp02RUMGeHNMNQV7Lkf2R8KGbLZ3hW0LJbun62yWXv2pztsynDaleG0a4Sj+9b5rn1Oe3cY7ZDX194dYsJBprdLY6TZLCoY6Y62tI3NcWtMTri1Ldudpua2Tr3TGlBza/j2ndZONbcF9I6/U01tAZ3u6JLDZpUrzda9WeWy2+SM3E+zyWm3qjMYUntnSO2dwfBtV1AdkfudQbV3hT8dkVBpt1pltar7Nvz+rRaLHHZLz2vZe17D3f16zu777jSb0h02uR02pTvsSneEn5PuCD821IJcKGTodKBLbYFg+HftsMliGdh76AyG9Iq3RS++2aS/HGnWi2826R+NLXrvepz/++JRSZLDZtUlBVm67LwcXXreSF02LkcF2a646mEYhto7Q2oNdKk1EFRbZ1CtgaBaA13q6AxphMuunPTwHwjZ7rToHxcYvIzuPzyH2r+pgYgr1OTm5spms6mxsTFmf2NjozweT6/P8Xg8fZaP3DY2Nio/Pz+mzNSpU+OpXgyn0ymn09nv5w8HI5x2XeTJ1EWe3oNPS3un2jtDMozwl3ik1cMwIq0g4U0Kt97Yur+8rN1f7Farult2LNFrVjW3dcrXffve+/5Al+xWq+w2ixy28G2azdq9hb8s7VaLDCkmaETvd29dIaO7hSnSymSJaXEK/2xRe2dQb/sDescf0Nv+gE75O3TKH1Bn0FBbZ1BvNQ2u8OW0W+XJdikYMnSsuV2dQUNvvN2qN95ulfR2qqtnGqfd+p6WOqts3SEqss9qCUdww+huRTRiWxKN7s+N1WKRPfLZsoWfmxYJo91B1W6zymm3ytH9WXTYe26d9vBnU5J8bV3ytXd/rts75WvrUnNbp1raO2PChtUS/reX6Qq3Uma67Mpy2ZXlStOI7hAd6AqpoyukQFdIgWCo++egAl3hgHn4bb8CXe9fwuHcTKemFI7UlLHZslgs2t/wjvY3NOltf0AHjjTpwJEm6fmeshfmZSrUHdYDwVC4lbTLUGcopK53tZBGQsyHHWFptUgj0x3KSU/TqAxHNOxkOO3vCs89wTl8G95nt1qiv7NgSO+633NrtViU5Q6fs0hrb5YrTa40a59BzTAMdXSF1BYIqrUzqPbO2ED+3v+7Ivs6OkPyd3TpdEeX/B1d8ge65O8IvmtfUCHDUKYr/MdJhtOuEd3337250mwy1P05DBnR7vno/6chqSsUPt8t7eFjn27v0umOzpif/YGgRjhtyslwaFR6T2tzTka4pTnLlSar1SLDMHTidEf0D9U33/VH65vvtOqtd9pkSDo/N0MfOXeELjhnRPT2/HMyem2xDoUMHW/peNexwrfHWzrkTrNFz0Fm9+c58vke4Qx/1kePcGhsTvqH+yAlQVyhxuFwaNq0aaqtrVVFRYWk8EDh2tpa3Xjjjb0+p7S0VLW1tVq2bFl0386dO1VaWipJKioqksfjUW1tbTTE+Hw+1dfXn1UznVIh3NqTuOOdkzn4Q6RhGDrd0aVT/oBO+QPydwSjX3BWS+/dXlaL5V2BKhQNVu8OWoFg+D/S6H+KHV063RHU6Y5O+TvC+1sDXcpw2JWXFR7MfW6mU55sl/KyXMrLdCnLbY/+h90VDKmxpUNvdrewvdXU85/LW01t8rV1amR6+C/mnPQ05aQ7lN19OzI9TSPTHcp02tXR/WXZ0d0C0/7uFpjO8GNp0dac7lu7tac1xx5uRZFFCgZ7D5mR8xFu8elp7WkLBNXR1fN6bZ3hfe3RFoCe+23dXz6SwnVO1QdkAKwWdX+B9bRaDiQ4Z7nsmlI4UpPHZmvy2JGaMnakPNnv/wdrGIYaTrVqf0OT9je8o30NTfr7MZ+Ot3ToeEv/zqTTblV6d0ua2xEOJv6OLr3tD6ilvUshQ9F/Q6+d8Pf7PcYrzWYJhxxXmtKdNnV0hqKfq7bO+ILZUBYJlf6OLnX0En7f62Vvi172tsTss1ikwpx0XXDuCOWOcOhoU7vefKdVR5vaFRjAmmil54/WL5Zc0e/nD1Tc3U+VlZVauHChpk+frhkzZmj9+vXy+/1atGiRJGnBggUaM2aMqqurJUlLly7V7NmztW7dOs2dO1dbtmzRnj179OCDD0oKj+NYtmyZ7r77bhUXF6uoqEirV69WQUFBNDhJUkNDg06dOqWGhgYFg0EdOHBAknTBBRdoxIgRAzwNOFtYLJZo19240Rmprs4Z2W1WjRnp1piRbpWkujImCIWMaBBq6wzGhqYzdAtaFG49tFh6Wm8iLXeRn0NG+C/j8FguQ13d47Y6Q4aC0dYKQ4FgUJ1dhjq6W006u28j9w2FQ8a7Ww3CY8Xs0Z+ddqs6ukLRVpyW9s7uwfzhFp6W9k6dbu+SzRpuBYpsTntPS1Fk39icdI0fnf6huo8sFovGjc7QuNEZqrh0jKTw+Ju/vtWsI6daY1pEo62kVovS7FalWa1Ks1vC3YKREJNm67NrqTMYCnd3+jt1yh/QO62BaIuov7ur6t1htqMrEnbD99/dghb5XUVbT7r/iAgZhlrau6Ktvb72rvDvLWjo5OmATp4OfOB5cditctnDq5ZEWk56Gw8YkdHdfRxpiUl32KL3M5x2WSwK/7ESaVGJ/vES3to7+w4C0c+n1RLbwuOyK/M9LT9uh02tgWD4/Ha3NL/TGg6R7w6VkePmZ0e6pnsmg4zNcaswJ10hw9BrJ07r1eOxm6+9Sw2nWtVw6v1rn9msFuVnu1QYPVa68rKc6ugK9XyuOyKTVcKf68j93oK3meIONfPmzdOJEydUVVUlr9erqVOnaseOHdGBvg0NDbJae5a/mTlzpjZv3qxVq1Zp5cqVKi4u1vbt2zVx4sRomeXLl8vv92vJkiVqamrSrFmztGPHDrlcPSenqqpK//3f/x39+dJLL5UkPfPMM7ryyivjfuMABg+r1dI9vmZoD/OLjCnqY6ibKdwOm2YUjdKMolEJP3aazapzM106N5HNvB/AMAy1BoIxXX/+ji4506zdY7Ts0WDm7h6b9UFjfiJdlEHDUFr3+LCB6AyGuxTfHa7fHWQSJdAVUlNrQKdaA8pw2OXJdinN1veSc+NGZ+hfJ/RMxjGMcDh89fhpvXritN7xB3rG7+W45clyyf4Bxxys4l6nZqga6uvUAABwNorn+3toRjEAAID3INQAAIBhgVADAACGBUINAAAYFgg1AABgWCDUAACAYYFQAwAAhgVCDQAAGBYINQAAYFgg1AAAgGGBUAMAAIYFQg0AABgWCDUAAGBYsKe6AmaJXIzc5/OluCYAAODDinxvR77H+3LWhJqWlhZJUmFhYYprAgAA4tXS0qLs7Ow+y1iMDxN9hoFQKKSjR48qMzNTFoslocf2+XwqLCzUkSNHlJWVldBj4/043+bifJuL820uzre5+nO+DcNQS0uLCgoKZLX2PWrmrGmpsVqtGjt2bFJfIysri38UJuJ8m4vzbS7Ot7k43+aK93x/UAtNBAOFAQDAsECoAQAAwwKhJgGcTqfWrFkjp9OZ6qqcFTjf5uJ8m4vzbS7Ot7mSfb7PmoHCAABgeKOlBgAADAuEGgAAMCwQagAAwLBAqAEAAMMCoWaANm3apPHjx8vlcqmkpES7d+9OdZWGjT/+8Y/6zGc+o4KCAlksFm3fvj3mccMwVFVVpfz8fLndbpWVlenQoUOpqewQV11drcsvv1yZmZk699xzVVFRoVdeeSWmTHt7u2644QaNHj1aI0aM0Oc//3k1NjamqMZD249+9CNNnjw5ugBZaWmpnnrqqejjnOvkuueee2SxWLRs2bLoPs554tx+++2yWCwx24QJE6KPJ/NcE2oGYOvWraqsrNSaNWu0b98+TZkyReXl5Tp+/HiqqzYs+P1+TZkyRZs2ber18bVr12rDhg2qqalRfX29MjIyVF5ervb2dpNrOvQ9++yzuuGGG/TnP/9ZO3fuVGdnpz75yU/K7/dHy3znO9/R//7v/2rbtm169tlndfToUX3uc59LYa2HrrFjx+qee+7R3r17tWfPHv3rv/6rrr76av3tb3+TxLlOphdeeEE//vGPNXny5Jj9nPPE+uhHP6pjx45Ftz/96U/Rx5J6rg3024wZM4wbbrgh+nMwGDQKCgqM6urqFNZqeJJkPPbYY9GfQ6GQ4fF4jHvvvTe6r6mpyXA6ncYvfvGLFNRweDl+/LghyXj22WcNwwif27S0NGPbtm3RMn//+98NSUZdXV2qqjms5OTkGD/5yU8410nU0tJiFBcXGzt37jRmz55tLF261DAMPt+JtmbNGmPKlCm9Ppbsc01LTT8FAgHt3btXZWVl0X1Wq1VlZWWqq6tLYc3ODocPH5bX6405/9nZ2SopKeH8J0Bzc7MkadSoUZKkvXv3qrOzM+Z8T5gwQeeddx7ne4CCwaC2bNkiv9+v0tJSznUS3XDDDZo7d27MuZX4fCfDoUOHVFBQoPPPP19f/vKX1dDQICn55/qsuaBlop08eVLBYFB5eXkx+/Py8vTyyy+nqFZnD6/XK0m9nv/IY+ifUCikZcuW6WMf+5gmTpwoKXy+HQ6HRo4cGVOW891/f/3rX1VaWqr29naNGDFCjz32mC655BIdOHCAc50EW7Zs0b59+/TCCy+87zE+34lVUlKihx9+WBdddJGOHTumO+64Q//v//0/HTx4MOnnmlADIMYNN9yggwcPxvSBI/EuuugiHThwQM3NzfrlL3+phQsX6tlnn011tYalI0eOaOnSpdq5c6dcLleqqzPsfepTn4renzx5skpKSjRu3Dg9+uijcrvdSX1tup/6KTc3Vzab7X0jthsbG+XxeFJUq7NH5Bxz/hPrxhtv1BNPPKFnnnlGY8eOje73eDwKBAJqamqKKc/57j+Hw6ELLrhA06ZNU3V1taZMmaL777+fc50Ee/fu1fHjx3XZZZfJbrfLbrfr2Wef1YYNG2S325WXl8c5T6KRI0fqwgsv1Kuvvpr0zzehpp8cDoemTZum2tra6L5QKKTa2lqVlpamsGZnh6KiInk8npjz7/P5VF9fz/nvB8MwdOONN+qxxx7T008/raKiopjHp02bprS0tJjz/corr6ihoYHznSChUEgdHR2c6yS46qqr9Ne//lUHDhyIbtOnT9eXv/zl6H3OefKcPn1ar732mvLz85P/+R7wUOOz2JYtWwyn02k8/PDDxksvvWQsWbLEGDlypOH1elNdtWGhpaXF2L9/v7F//35DknHfffcZ+/fvN9544w3DMAzjnnvuMUaOHGn85je/Mf7yl78YV199tVFUVGS0tbWluOZDzze/+U0jOzvb+MMf/mAcO3YsurW2tkbLfOMb3zDOO+884+mnnzb27NljlJaWGqWlpSms9dB12223Gc8++6xx+PBh4y9/+Ytx2223GRaLxfj9739vGAbn2gzvnv1kGJzzRLr55puNP/zhD8bhw4eN559/3igrKzNyc3ON48ePG4aR3HNNqBmgBx54wDjvvPMMh8NhzJgxw/jzn/+c6ioNG88884wh6X3bwoULDcMIT+tevXq1kZeXZzidTuOqq64yXnnlldRWeojq7TxLMh566KFomba2NuNb3/qWkZOTY6SnpxvXXHONcezYsdRVegj76le/aowbN85wOBzGOeecY1x11VXRQGMYnGszvDfUcM4TZ968eUZ+fr7hcDiMMWPGGPPmzTNeffXV6OPJPNcWwzCMgbf3AAAApBZjagAAwLBAqAEAAMMCoQYAAAwLhBoAADAsEGoAAMCwQKgBAADDAqEGAAAMC4QaAAAwLBBqAADAsECoAQAAwwKhBgAADAuEGgAAMCz8f7boHuSuIa0DAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 50\n",
    "batch_size = 72\n",
    "train_loss = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    permutation = torch.randperm(train_X.size(0))\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for i in range(0, train_X.size(0), batch_size):\n",
    "        indices = permutation[i:i + batch_size]\n",
    "        batch_X, batch_y = train_X[indices], train_y[indices]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    train_loss.append(epoch_loss / (train_X.size(0) // batch_size))\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {train_loss[-1]:.4f}\")\n",
    "\n",
    "# Plot training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 26.811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    yhat = model(test_X)\n",
    "    yhat = yhat.numpy()\n",
    "    test_X = test_X.numpy().reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "    # Invert scaling for forecast\n",
    "    inv_yhat = np.concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:, 0]\n",
    "\n",
    "    # Invert scaling for actual\n",
    "    test_y = test_y.numpy()\n",
    "    inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "    inv_y = scaler.inverse_transform(inv_y)\n",
    "    inv_y = inv_y[:, 0]\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "    print(f'Test RMSE: {rmse:.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
